{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_test.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "2QbRX_rWT6X6",
        "colab_type": "code",
        "outputId": "80a5b1c0-aeaa-43ae-8d6d-978ba726791f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import nltk\n",
        "import pickle\n",
        "import random\n",
        "import argparse\n",
        "import csv\n",
        "import os\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from gensim.models import FastText,Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, strip_non_alphanum\n",
        "import nltk\n",
        "from nltk import sent_tokenize,word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import model_from_json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "f_KRKgWvUEP9",
        "colab_type": "code",
        "outputId": "41912c4a-f705-4736-bbeb-6a36f889d547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')  \n",
        "for file in os.listdir('.'):\n",
        "  print(file)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Untitled0.ipynb\n",
            "Word2Vec.ipynb\n",
            "vector_avg.ipynb\n",
            "Doc2Vec.ipynb\n",
            "news_cleaned_combined_ctext.txt\n",
            "vector.pkl\n",
            "newsCleaned_final.txt\n",
            "news_cleaned_combined_ctext_final.txt\n",
            "vector_summary.ipynb\n",
            "text_token.txt\n",
            "word2vec.model\n",
            "newsCleaned_ctxt.txt\n",
            "newsCleaned.txt\n",
            "bbc_pkl\n",
            "bbc_ft.bin\n",
            "model.ipynb\n",
            "Untitled1.ipynb\n",
            "bbc_short_sum_pkl\n",
            "models\n",
            "vector_text.ipynb\n",
            "model_bbc_short_summary.ipynb\n",
            "Untitled2.ipynb\n",
            "weights_satisfied.hdf5\n",
            "outputs.npy\n",
            "inputs.npy\n",
            "model.json\n",
            "model.h5\n",
            "model_bbc.ipynb\n",
            "model_test.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "btslanvlULCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "allWords = []\n",
        "MAX_SENTENCE_LEN = 35\n",
        "EMBEDDING_SIZE = 100\n",
        "# p is the index into our training data for where we are now.\n",
        "p = 0\n",
        "accuracy_print_interval = 5\n",
        "# number of neurons in each layer\n",
        "input_num_units = MAX_SENTENCE_LEN*EMBEDDING_SIZE\n",
        "hidden_num_units = 1500\n",
        "output_num_units = MAX_SENTENCE_LEN\n",
        "epochs = 250\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "model_ft = FastText.load('bbc_ft.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DydXzKgzUQjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_str(string):\n",
        "    string = re.sub(r\"\\'s\", \"\", string)\n",
        "    string = re.sub(r\"\\'ve\", \"\", string)\n",
        "    string = re.sub(r\"n\\'t\", \"\", string)\n",
        "    string = re.sub(r\"\\'re\", \"\", string)\n",
        "    string = re.sub(r\"\\'d\", \"\", string)\n",
        "    string = re.sub(r\"\\'ll\", \"\", string)\n",
        "    string = re.sub(r\",\", \"\", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \"\", string)\n",
        "    string = re.sub(r\"\\)\", \"\", string)\n",
        "    string = re.sub(r\"\\?\", \"\", string)\n",
        "    string = re.sub(r\"'\", \"\", string)\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"[0-9]\\w+|[0-9]\",\"\", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = re.sub(r\"\\n\",'',string)\n",
        "    string = re.sub(r\"  \",\" \",string)\n",
        "    return string.strip().lower()\n",
        "  \n",
        "def extract_sentences_from_paragraph(paragraph):\n",
        "    sentences = sent_tokenize(paragraph)\n",
        "    sent_list=[]\n",
        "    for s in sentences:\n",
        "      if(len(s.strip()) != 0):\n",
        "        s=clean_str(s)\n",
        "        new_s=' '\n",
        "        for w in word_tokenize(s):\n",
        "          new_s.join(lemmatizer.lemmatize(w))\n",
        "        sent_list.append(s)\n",
        "    return sent_list\n",
        "    #return [clean_str(s) for s in sentences if len(s.strip()) != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-1dM_9MUUhID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_array_vectorize(text):\n",
        "  texts=[]\n",
        "  texts.append(extract_sentences_from_paragraph(text))\n",
        "  nested_list_len = lambda x: sum(len(list) for list in x)\n",
        "  source_text_vectors = np.zeros((nested_list_len(texts), 3500))\n",
        "  vec_idx = 0\n",
        "  if(type(texts[0]) == list):\n",
        "      for i in range(len(texts)):\n",
        "          sentences = texts[i]\n",
        "          sentences_container = []\n",
        "          # Get text vector\n",
        "          for s in sentences:\n",
        "              sentence_vector = np.array([])\n",
        "              s=remove_stopwords(strip_punctuation(strip_non_alphanum(str(s).lower())))\n",
        "              s=clean_str(s)\n",
        "              for w in word_tokenize(s):\n",
        "                  w=lemmatizer.lemmatize(w)\n",
        "                  if(model_ft.__contains__(w)==False):\n",
        "                    continue\n",
        "                  if(len(sentence_vector) < MAX_SENTENCE_LEN*EMBEDDING_SIZE):\n",
        "                      sentence_vector = np.append(sentence_vector, model_ft[w])\n",
        "                  else:\n",
        "                      break\n",
        "              while(len(sentence_vector) < MAX_SENTENCE_LEN*EMBEDDING_SIZE):\n",
        "                  sentence_vector = np.append(sentence_vector,np.zeros(EMBEDDING_SIZE))\n",
        "              source_text_vectors[vec_idx] = sentence_vector\n",
        "              vec_idx+=1\n",
        "  return (source_text_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-3lmF_wWGbMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9927ca11-7a4b-4626-b72c-9a3d1aa4dd27"
      },
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, strip_non_alphanum\n",
        "text='Tacit approval from the White House for the weaker greenback, which could help counteract huge deficits . European single currency has shot up to successive all-time highs against the dollar over the past few months. she is in good form.Tacit approval from the White House for the weaker greenback, which could help counteract huge deficits . European single currency has shot up to successive all-time highs against the dollar over the past few months. she is in good form.Tacit approval from the White House for the weaker greenback, which could help counteract huge deficits . European single currency has shot up to successive all-time highs against the dollar over the past few months. she is in good form.'\n",
        "words=text.split(' ')\n",
        "print(len(words))\n",
        "clean=' '\n",
        "if(len(words)>35):\n",
        "  text=remove_stopwords(text)\n",
        "  words=text.split(' ')\n",
        "  print(len(text.split()))\n",
        "  if(len(words)>35):\n",
        "    words=words[:35]\n",
        "    print(len(words))\n",
        "    print(' '.join(w for w in words))\n",
        "else:\n",
        "  print(text)\n",
        "    \n",
        "    \n",
        "# arr_text=extract_sentences_from_paragraph(text)\n",
        "# for sent is \n",
        "def make_text_35(text):\n",
        "  words=text.split(' ')\n",
        "  if(len(words)>35):\n",
        "    text=remove_stopwords(text)\n",
        "    words=text.split(' ')\n",
        "    if(len(words)>35):\n",
        "      words=words[:35]\n",
        "    return (clean.join(w for w in words))\n",
        "  else:\n",
        "    return(text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118\n",
            "67\n",
            "35\n",
            "Tacit approval White House weaker greenback, help counteract huge deficits . European single currency shot successive all-time highs dollar past months. good form.Tacit approval White House weaker greenback, help counteract huge deficits . European single\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hl1E9qw9ZxMe",
        "colab_type": "code",
        "outputId": "7609f913-6802-4444-b640-10de8b4c625c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "text=\"Sorting the arrays indexes by their associated probability/'s in descending order.Grabbing the first two class label indices which are thus the top-2 predictions from our network.How is this done is what we will learn.My name is adotya jain. I study is pesu\"\n",
        "print(extract_sentences_from_paragraph(text))\n",
        "vec=make_array_vectorize(text)\n",
        "print(vec.shape)\n",
        "print(vec)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sorting the arrays indexes by their associated probability in descending order grabbing the first two class label indices which are thus the top predictions from our network how is this done is what we will learn my name is adotya jain', 'i study is pesu']\n",
            "(2, 3500)\n",
            "[[ 0.2001051   0.34322619 -0.39303607 ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.01239833  0.17048369 -0.3352603  ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pyd7M_ohbHxY",
        "colab_type": "code",
        "outputId": "65b1cada-0f6e-40be-8ff9-9e2c4b777fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "results=loaded_model.predict(vec)\n",
        "for res in results:\n",
        "  word_idx=sorted(range(len(res)), key=lambda i: res[i], reverse=True)[:15]#making top 15 values as 1\n",
        "  for i in word_idx:\n",
        "    res[i]=1\n",
        "print(results)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Loaded model from disk\n",
            "[[1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
            "  2.6960557e-03 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
            "  1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
            "  1.0000000e+00 9.2376882e-05 2.0519286e-08 2.7548802e-10 2.5186222e-07\n",
            "  1.2968289e-17 2.5110858e-17 1.5852445e-14 1.0220711e-14 2.1602152e-14\n",
            "  3.0502991e-14 3.1671904e-14 1.3987813e-14 3.6845811e-14 4.3077195e-14\n",
            "  2.9193167e-14 3.2400603e-14 3.3685707e-14 3.6730242e-14 4.0248973e-14]\n",
            " [1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
            "  1.0000000e+00 5.6972341e-13 1.2738887e-11 1.0000000e+00 1.0000000e+00\n",
            "  1.0000000e+00 1.0000000e+00 3.9188086e-13 1.0000000e+00 4.6353714e-13\n",
            "  3.2648409e-12 2.9304985e-13 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
            "  1.0000000e+00 1.8294773e-14 2.8019123e-13 3.9337335e-17 5.6703509e-16\n",
            "  3.1917665e-16 2.4745390e-16 2.4274919e-16 3.6602999e-16 4.3496820e-16\n",
            "  5.8456618e-16 6.5703239e-16 6.7955876e-16 8.3049383e-16 6.9527080e-16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lc3D5hOPMTd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4f8ad872-4e6f-48bf-8163-244082fdbd74"
      },
      "cell_type": "code",
      "source": [
        "# text = \"The European single currency has shot up to successive all-time highs against the dollar over the past few months.\"\n",
        "# text='Tacit approval from the White House for the weaker greenback, which could help counteract huge deficits . European single currency has shot up to successive all-time highs against the dollar over the past few months.'\n",
        "# print(extract_sentences_from_paragraph(text))\n",
        "text=\"The European single currency has shot up to successive all-time highs against the dollar over the past few months. Tacit approval from the White House for the weaker greenback, which could help counteract huge deficits, has helped trigger the move. But now Europe says the euro has had enough, and Asia must now share some of the burden.\"\n",
        "arr_text=extract_sentences_from_paragraph(text)\n",
        "vec=make_array_vectorize(text)\n",
        "print(vec.shape)\n",
        "results=loaded_model.predict(vec)\n",
        "# ck=results.copy()\n",
        "for res in results:\n",
        "  word_idx=sorted(range(len(res)), key=lambda i: res[i], reverse=True)[:15]\n",
        "  for i in word_idx:\n",
        "    res[i]=1\n",
        "# for res in results:\n",
        "#   for sent in sent_tokenize(text):\n",
        "# #     print(sent)\n",
        "#     print( \" \".join([word for idx,word in enumerate(sent.split(\" \")) if(res[idx] == 1)])) \n",
        "for res,sent in zip(results,arr_text):\n",
        "  sent=make_text_35(sent)\n",
        "  print( \" \".join([word for idx,word in enumerate(sent.split(\" \")) if(res[idx] == 1)])) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3500)\n",
            "the european single currency has shot up to successive all time over the past few\n",
            "tacit approval from the white house for the weaker greenback which could help deficits helped\n",
            "but now europe says the euro has had the burden\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "szzMGrAdYbkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "46ec7212-2439-4d1e-af35-96e51d11fa6a"
      },
      "cell_type": "code",
      "source": [
        "# # Import BeautifulSoup from bs4\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# # Create a BeautifulSoup object from the HTML\n",
        "# soup = BeautifulSoup('https://machinelearningmastery.com/clean-text-machine-learning-python/', \"html5lib\")\n",
        "# type(soup)\n",
        "# bs4.BeautifulSoup\n",
        "# text = soup.get_text()\n",
        "# print(text)\n",
        "# !pip install html2text\n",
        "# import urllib.request\n",
        "# html = urllib.request.urlopen('https://machinelearningmastery.com/clean-text-machine-learning-python/')\n",
        "# soup = BeautifulSoup(html)\n",
        "# data = soup.findAll(text=True)\n",
        "# print(data)\n",
        "\n",
        "# import html2text\n",
        "# print(html2text.html2text(html))\n",
        "# from goose import Goose\n",
        "# g = Goose()\n",
        "# article = g.extract('https://machinelearningmastery.com/clean-text-machine-learning-python')\n",
        "\n",
        "# # process/store ...\n",
        "# print(article.cleaned_text)\n",
        "import urllib.request\n",
        "import json\n",
        "user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
        "\n",
        "# url = \"https://www.reuters.com/article/us-uber-ceo-idUSKBN19C0G6\"\n",
        "url=\"https://contentxtractor.com/api/v1/?a=grab&key=12jopu98&url=https://www.joe.co.uk/fitness-health/how-to-train-like-an-olympian-and-get-the-ultimate-lean-phyqiue-79681\"\n",
        "headers={'User-Agent':user_agent,} \n",
        "\n",
        "request=urllib.request.Request(url,None,headers) #The assembled request\n",
        "response = urllib.request.urlopen(request)\n",
        "data = response.read() # The data u need\n",
        "output = json.loads(data)\n",
        "print (output)\n",
        "print(output['data']['text'])\n",
        "\n",
        "def test_with_url(url):\n",
        "  url='https://contentxtractor.com/api/v1/?a=grab&key=12jopu98&url='+str(url)\n",
        "  headers={'User-Agent':user_agent,} \n",
        "  request=urllib.request.Request(url,None,headers) #The assembled request\n",
        "  response = urllib.request.urlopen(request)\n",
        "  data = response.read() # The data u need\n",
        "  output = json.loads(data)\n",
        "  print (output)\n",
        "  print(output['data']['text'])\n",
        "  text=output['data']['text']\n",
        "  arr_text=extract_sentences_from_paragraph(text)\n",
        "  print(len(arr_text))\n",
        "  vec=make_array_vectorize(text)\n",
        "  print(vec.shape)\n",
        "  results=loaded_model.predict(vec)\n",
        "  for res in results:\n",
        "    word_idx=sorted(range(len(res)), key=lambda i: res[i], reverse=True)[:15]\n",
        "    for i in word_idx:\n",
        "      res[i]=1\n",
        "  sent_sum=' '\n",
        "  for res,sent in zip(results,arr_text):\n",
        "    sent=str(make_text_35(sent))\n",
        "    s_indv=' '.join([word for idx,word in enumerate(sent.split(\" \")) if(res[idx] == 1)])\n",
        "    sent_sum=str(sent_sum)+str(s_indv)+str(',')\n",
        "    print(s_indv)\n",
        "  return sent_sum\n",
        "     "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': {'title': 'How to train like an Olympian and get the ultimate lean physique', 'text': \"If you've not noticed, the Olympics are on and the athletes are all in incredible shape. But right at the top of the tree in terms of body composition are the Olympic sprinters (yes we know - the weightlifters and gymnasts are pretty damn hench too). The likes of 100m king Usain Bolt and Team GB sprinterHarry Aikines-Aryeeteyare lean, muscular and shredded all year round. It's the physique that so many of us are trying to achieve slogging our guts out in the gym - and it's trainingthe bigger fast-twitch muscle fibres for maximal power helps build them into physical specimens. But if you want to look like an Olympian then you're probably going to have to train and eat like one. Sarah Claxtonis a former Olympic hurdlerwho now uses her knowledge of training and nutrition to get people in the best shape of their lives at London's Embody Fitness. The ex-English athlete specialises in the 100m hurdlesand competed atthe 2004 and 2008 Olympic Games - finishing eighth at the latter Games - and boastsa lifetime best of 12.81 seconds, which remains in the top four British all-time best list. Like most sprint athletes, her training was based around speed and power - but it brought incredible body composition benefits. We spoke to her about how sprinters train to make them faster, stronger and more powerful athletes and how this training translates into the gym to people she coaches for body transformations looking for the ultimate lean physique. How did you train as a sprint athlete? I did long jump first. Then I switched to hurdles. So I was training six days a week for three or four hours a day. We had running sessions first – sprints on a track. Then we would have weights afterwards and then plyometrics after that. Monday, Wednesday, Friday, then intensity would be quite high. Then Tuesday and Thursday it would be lower because you can't train with such high intensity every single day because you would just breakdown and get injuries and things like that. So on a Monday we'd get to the track and warm up for an hour. Probably then do some sprint starts to the first hurdle or a long running session – that would be a good hour and a half. Then after that we would go into the gym and do a weights session as well. Then it would be a plyometrics session – so standing long jumps, box jumps, hurdle rebounds which is where you have five hurdles spread out and you would bound over them So explain the running element- what was the goal of the trainingat and what were the techniques involved? So the sprinting part it would be to either practice a certain movement over the hurdles – breaking the movement down into different sections. Or just to again practice a block start or a general conditioning session. During the winter we would do ten 300m runs with two or three minutes rest in between. Or we would have 30-second, 60-second and 90-second runs on the grass. We would also do 150m sprints where we'd do six of them. So it was pretty intense. The rests in between mean you can recover and go 100% again. But as the session goes on you get more tired but that's when you have to push more to build up the lactic tolerance. How does that training build up your lactic tolerance and how did it improve your performance? Because our event was speed endurance – even though it's a flat-out sprint there is endurance in there towards the end – because we're doing it over distance we're in a lactic state and we're trying to push your body through that, the body gets used to being in that state. So when it comes to a race we've already been in that condition already, so during a race it's easier for us to hold on and keep our form better. What kind of workwere you doing in the gym? We would probably do two gym sessions a week. Any more and we would have been a bit too heavy. We want to stay light but still be powerful and explosive. During the winter we would do heavier weights and more reps. So we would be doing cleans, squats and deadlifts. Then also doing isolation work on our hamstrings, quads and a lot of core work because of the position you have to hold going over a hurdle you need to be strong in your core. As it goes on through the season it would be lighter weights but quicker on the movements. Everything we did was quick, nothing was slow like you would normally do in the gym. We would be targeting different muscle fibres – we would always want to keep the fast twitch fibres conditioned. Did you find the gym work helped you become a better athlete? Yes it did, because we would do the gym where everything would be fast and explosive then you would come out and do plyometrics which correlated to what we were doing in the gym. You would feel bouncy and really fast. What kind of things were you doing with plyometrics and how did that improve your performance? We would do bunny hops over hurdles – so trying to make the least contact with the floor as possible. So we had to jump but as soon as you touch the floor you had to rebound and jump over the next hurdle, rather than sinking into the floor and going again. Because when we're sprinting we want our foot contact to be quite quick off the ground, so doing plyometrics where the contact is less on the floor, it really helps our sprinting. With the movement on the plyometrics it crosses over to sprinting. It gets the hip flexors involved as well. When you moved from athletics to what you do now, does a lot of it translate over? I was actually quite surprised by how different it is. With track and field everything is explosive and fast but with personal training you have to slow everything down so people can feel what muscles are moving and they can get the benefits of the weight training. The timings are obviously different as well – we would get a lot longer recovery because everything is so much more explosive. Whereas when someone is trying to get fit their recovery time is less. What elements from your athletics career benefit people who are looking to improve their body composition. It's all mental with a lot of people. They can push themselves to a certain limit, but they don't know how to get past that barrier. Whereas I know how to get them past that and get that extra little bit out of them. So being an athlete really helps with that. I tell them I've been through it and yes you're going to feel sick and feel bad in the hour, but afterwards you're going to feel really good. The weights they're using are getting heavier and they're getting stronger so it shows they are improving. What are the successful components to a good body transformation? Obviously a good diet – what they're eating is so important. Then in the gym it's a weights-based session followed by an interval session as well, so it raises their heart rate which carries over to the next day because their metabolism kicks up. The reps change throughout the transformation too. So we start around 12 reps then as each session goes on it drops down to 8-10s and then 6-8s as well. This is so the body doesn't plateau. It keeps your body on its toes, so to speak, so you don't get used to one way of training. People want to stay in their comfort zone but I have to try and push people out of that. Does some of your athlete training – particularly the spring interval work – carry over to helping people transform their physiques? Yes definitely. Especially the cardio at the end of the sessions. It's very beneficial. If you want a transformation and you want to lose fat, doing intervals will really help. It's because you're keeping the heart rate raised and keeping changing the interval durations. What are the things that are important to build muscle – things you've done as an athlete – that can be important for transformations. Definitely working on cycles for hypertrophy and using compound lifts as well. Recovery time [in between lifts] is key too. If you're just having one minute rest in between sets then you're not going to build any muscle. But if you're having two or three minutes in between each lift, then you will be doing enough damage to the muscle fibres in order for them to grow. If you're doing a more cardio-based workout (lower weight, higher reps) then you'll need less recovery. If you want to build muscle then just extend the time you're resting or recovering. We mainly use barbells and dumbbells work and focus on compound lifts. Then at the end do bodyweight circuits, rowing or bike intervals or sprinting as well. What is the best nutrition strategy for body composition then? Where I work, we have someone working specifically on nutrition. But the first 12 or 14 days they're off carbs – so just veg, good fats and protein. That shocks the body into using the fat stores as energy rather than storing it. Then after that they have a carb refeed so like sweet potato, oats or quinoa after a session. Then they only have carbs on the days they're at the gym. So it's carb cycling. It gets really good results – as long as people are sticking to it – and you can tell when they're not. But for the most part they do and they get really good results. It is almost the same as when I was an athlete. As a sprinter I didn't need that many carbs. Obviously I would have them on days that I was training. But if I was a long distance runner I would need more carbs for fuel. I was probably on about 2,000 calories a day – and the max was around 2,500. Some of the guys would be on more, but I always felt if I ate too much I felt too heavy. What key tips can people take from your time as an athlete to improve their health, their fitness or their body? Definitely do compound lifts in the gym. Also interval cardio rather than plodding along on a treadmill for 20 minutes because the heart rate goes up and down so you get more metabolic change rather than just being at one speed on a treadmill and you will get fitter quicker that way. Carb cycling is another big one – having a week off carbs and getting plenty of good fats like nuts and seeds. Then having a re-feed of good carbs like quinoa or oats. What exercise would it be to get the most benefit from? My favourite exercise is deadlift. It's a whole body workout. It literally works everything. Either trap bar deadlift or just a regular barbell, it's good to mix it up. Embody Fitness is an Olympic-standard personal training and body transformation studio in Bank, London. For more information please visit www.embodyfitness.co.uk Read more:\", 'images': {'0': 'https://img.maximummedia.ie/joe_co_uk/eyJkYXRhIjoie1widXJsXCI6XCJodHRwOlxcXC9cXFwvbWVkaWEtam9lY291ay5tYXhpbXVtbWVkaWEuaWUuczMuYW1hem9uYXdzLmNvbVxcXC93cC1jb250ZW50XFxcL3VwbG9hZHNcXFwvMjAxNlxcXC8wOFxcXC8xNTE3NDcyOVxcXC9ib2x0dC0xMDI0eDUxMS5qcGdcIixcIndpZHRoXCI6NjQ3LFwiaGVpZ2h0XCI6MzQwLFwiZGVmYXVsdFwiOlwiaHR0cHM6XFxcL1xcXC93d3cuam9lLmNvLnVrXFxcL2Fzc2V0c1xcXC9pbWFnZXNcXFwvam9lY291a1xcXC9uby1pbWFnZS5wbmc_aWQ9MjY0YTJkYmUzNzBmMmM2NzVmY2RcIixcIm9wdGlvbnNcIjpbXX0iLCJoYXNoIjoiYjVkMWVjNjljNzJkYTlhMDM2OGM2MDg2NjRkNTY1NWJlN2ZmOWM0NSJ9/boltt-1024x511.jpg', '1': 'https://www.joe.co.uk//assets/images/joecouk/main-logo.svg?id=8967a11632c9277ef69f                                 ', '2': 'https://www.joe.co.uk//assets/images/youtube.png?id=777c0126377f95c815e6', '3': 'https://www.joe.co.uk//assets/images/instagram.png?id=817ba616cce7f1de5ba2', '4': 'https://img.maximummedia.ie/joe_co_uk/eyJkYXRhIjoie1widXJsXCI6XCJodHRwOlxcXC9cXFwvbWVkaWEtam9lY291ay5tYXhpbXVtbWVkaWEuaWUuczMuYW1hem9uYXdzLmNvbVxcXC93cC1jb250ZW50XFxcL3VwbG9hZHNcXFwvMjAxNlxcXC8wOFxcXC8xNTE3NDcyOVxcXC9ib2x0dC0xMDI0eDUxMS5qcGdcIixcIndpZHRoXCI6NzY3LFwiaGVpZ2h0XCI6NDMxLFwiZGVmYXVsdFwiOlwiaHR0cHM6XFxcL1xcXC93d3cuam9lLmNvLnVrXFxcL2Fzc2V0c1xcXC9pbWFnZXNcXFwvam9lY291a1xcXC9uby1pbWFnZS5wbmc_aWQ9MjY0YTJkYmUzNzBmMmM2NzVmY2RcIixcIm9wdGlvbnNcIjpbXX0iLCJoYXNoIjoiNjM5NGU1MzFkMzU0YTE1NWY3YjIxNzQ2MzlkZGRkOGJiMWIwOTBjMSJ9/boltt-1024x511.jpg', '5': 'https://www.gravatar.com/avatar/29719bb96149d0c992925f6e558cabf7.jpg?s=100&amp;d=mm', '6': 'https://m0.joe.co.uk/wp-content/uploads/2016/08/15172421/GettyImages-85271101.jpg', '7': 'https://img.maximummedia.ie/joe_co_uk/eyJkYXRhIjoie1widXJsXCI6XCJodHRwOlxcXC9cXFwvbWVkaWEtam9lY291ay5tYXhpbXVtbWVkaWEuaWUuczMuYW1hem9uYXdzLmNvbVxcXC93cC1jb250ZW50XFxcL3VwbG9hZHNcXFwvMjAxOVxcXC8wM1xcXC8yMDEyNTkyMVxcXC9TY3JlZW5zaG90LTIwMTktMDMtMjAtYXQtMTIuNTguNDUucG5nXCIsXCJ3aWR0aFwiOjI0MSxcImhlaWdodFwiOjE1MixcImRlZmF1bHRcIjpcImh0dHBzOlxcXC9cXFwvd3d3LmpvZS5jby51a1xcXC9hc3NldHNcXFwvaW1hZ2VzXFxcL2pvZWNvdWtcXFwvbm8taW1hZ2UucG5nP2lkPTI2NGEyZGJlMzcwZjJjNjc1ZmNkXCIsXCJvcHRpb25zXCI6W119IiwiaGFzaCI6ImVmZGZjNGMyNzY4MDE0ZGMzMzY0NTFiMGEyY2UxYjczOTdlODViNGMifQ==/screenshot-2019-03-20-at-12-58-45.png', '8': 'https://m0.joe.co.uk/wp-content/uploads/2016/08/15172447/GettyImages-82401307.jpg', '9': 'https://img.maximummedia.ie/joe_co_uk/eyJkYXRhIjoie1widXJsXCI6XCJodHRwOlxcXC9cXFwvbWVkaWEtam9lY291ay5tYXhpbXVtbWVkaWEuaWUuczMuYW1hem9uYXdzLmNvbVxcXC93cC1jb250ZW50XFxcL3VwbG9hZHNcXFwvMjAxOVxcXC8wMlxcXC8wNjE2MjM1N1xcXC9TY3JlZW4tU2hvdC0yMDE5LTAyLTA2LWF0LTE2LjIzLjA2LnBuZ1wiLFwid2lkdGhcIjoyNDEsXCJoZWlnaHRcIjoxNTIsXCJkZWZhdWx0XCI6XCJodHRwczpcXFwvXFxcL3d3dy5qb2UuY28udWtcXFwvYXNzZXRzXFxcL2ltYWdlc1xcXC9qb2Vjb3VrXFxcL25vLWltYWdlLnBuZz9pZD0yNjRhMmRiZTM3MGYyYzY3NWZjZFwiLFwib3B0aW9uc1wiOltdfSIsImhhc2giOiJkZGY4OTcxMzNlMzVmMWU0NmUxZmVkNmUwYjdkNjRhNTdjYThhMmZmIn0=/screen-shot-2019-02-06-at-16-23-06.png', '10': 'https://m0.joe.co.uk/wp-content/uploads/2016/08/15172654/GettyImages-79687288.jpg', '11': 'https://m0.joe.co.uk/wp-content/uploads/2016/08/15172717/GettyImages-82401230.jpg', '12': 'https://img.maximummedia.ie/joe_co_uk/eyJkYXRhIjoie1widXJsXCI6XCJodHRwOlxcXC9cXFwvbWVkaWEtam9lY291ay5tYXhpbXVtbWVkaWEuaWUuczMuYW1hem9uYXdzLmNvbVxcXC93cC1jb250ZW50XFxcL3VwbG9hZHNcXFwvMjAxOVxcXC8wMVxcXC8zMDE3NTAyNFxcXC9zcG9ydC0xMjQ0OTI1XzE5MjAtMTAyNHg2ODMuanBnXCIsXCJ3aWR0aFwiOjI0MSxcImhlaWdodFwiOjE1MixcImRlZmF1bHRcIjpcImh0dHBzOlxcXC9cXFwvd3d3LmpvZS5jby51a1xcXC9hc3NldHNcXFwvaW1hZ2VzXFxcL2pvZWNvdWtcXFwvbm8taW1hZ2UucG5nP2lkPTI2NGEyZGJlMzcwZjJjNjc1ZmNkXCIsXCJvcHRpb25zXCI6W119IiwiaGFzaCI6ImEzYWQyZGFmMjlmNmZkNGM1ODc2YWRmNDNhNDg1NmNiOTMzODkwZjkifQ==/sport-1244925-1920-1024x683.jpg', '13': 'https://m0.joe.co.uk/wp-content/uploads/2016/08/15172741/GettyImages-71619486.jpg', '14': 'https://m0.joe.co.uk/wp-content/uploads/2016/08/15172912/GettyImages-81671043.jpg', '15': 'https://m0.joe.co.uk/wp-content/uploads/2016/08/15172946/GettyImages-80167778.jpg', '16': 'https://m0.joe.co.uk/wp-content/uploads/2016/07/07230326/snapchat3-1024x1021.png', '17': 'https://m0.joe.co.uk/wp-content/uploads/2019/03/14152955/Boys-Dont-Cry.png', '18': 'https://m0.joe.co.uk/wp-content/uploads/2018/10/17154427/Podcasts-Icon.png', '19': 'https://m0.joe.co.uk/wp-content/uploads/2018/10/17154435/YouTube-Icon.png', '20': 'https://m0.joe.co.uk/wp-content/uploads/2018/10/17154431/Spotify-Icon.png', '21': 'https://m0.joe.co.uk/wp-content/uploads/2019/03/14155457/ASOS_Logo_Small.png', '22': 'https://img.maximummedia.ie/joe_co_uk/eyJkYXRhIjoie1widXJsXCI6XCJodHRwczpcXFwvXFxcL3d3dy5qb2UuY28udWtcXFwvYXNzZXRzXFxcL2ltYWdlc1xcXC9qb2Vjb3VrXFxcL25vLWltYWdlLnBuZz9pZD0yNjRhMmRiZTM3MGYyYzY3NWZjZFwiLFwid2lkdGhcIjoxMzMsXCJoZWlnaHRcIjo3NyxcImRlZmF1bHRcIjpcImh0dHBzOlxcXC9cXFwvd3d3LmpvZS5jby51a1xcXC9hc3NldHNcXFwvaW1hZ2VzXFxcL2pvZWNvdWtcXFwvbm8taW1hZ2UucG5nP2lkPTI2NGEyZGJlMzcwZjJjNjc1ZmNkXCIsXCJvcHRpb25zXCI6W119IiwiaGFzaCI6IjM3MmVmMDkzMDExMWEyYzJkMTM0YjEzN2VkY2I3NmFiYWFhNzgwZjYifQ==/no-image.png?id=264a2dbe370f2c675fcd', '29': 'https://img.maximummedia.ie/joe_co_uk/eyJkYXRhIjoie1widXJsXCI6XCJodHRwczpcXFwvXFxcL3d3dy5qb2UuY28udWtcXFwvYXNzZXRzXFxcL2ltYWdlc1xcXC9qb2Vjb3VrXFxcL25vLWltYWdlLnBuZz9pZD0yNjRhMmRiZTM3MGYyYzY3NWZjZFwiLFwid2lkdGhcIjozMTYsXCJoZWlnaHRcIjoxOTksXCJkZWZhdWx0XCI6XCJodHRwczpcXFwvXFxcL3d3dy5qb2UuY28udWtcXFwvYXNzZXRzXFxcL2ltYWdlc1xcXC9qb2Vjb3VrXFxcL25vLWltYWdlLnBuZz9pZD0yNjRhMmRiZTM3MGYyYzY3NWZjZFwiLFwib3B0aW9uc1wiOltdfSIsImhhc2giOiJlZmE3ZTkxYWJkMzIwYzE4MzhjOGMwMzRhN2ZkNDg1NzQ3MTk5NWVmIn0=/no-image.png?id=264a2dbe370f2c675fcd'}, 'publishingTime': False, 'language': 'en'}, 'result': 'success'}\n",
            "If you've not noticed, the Olympics are on and the athletes are all in incredible shape. But right at the top of the tree in terms of body composition are the Olympic sprinters (yes we know - the weightlifters and gymnasts are pretty damn hench too). The likes of 100m king Usain Bolt and Team GB sprinterHarry Aikines-Aryeeteyare lean, muscular and shredded all year round. It's the physique that so many of us are trying to achieve slogging our guts out in the gym - and it's trainingthe bigger fast-twitch muscle fibres for maximal power helps build them into physical specimens. But if you want to look like an Olympian then you're probably going to have to train and eat like one. Sarah Claxtonis a former Olympic hurdlerwho now uses her knowledge of training and nutrition to get people in the best shape of their lives at London's Embody Fitness. The ex-English athlete specialises in the 100m hurdlesand competed atthe 2004 and 2008 Olympic Games - finishing eighth at the latter Games - and boastsa lifetime best of 12.81 seconds, which remains in the top four British all-time best list. Like most sprint athletes, her training was based around speed and power - but it brought incredible body composition benefits. We spoke to her about how sprinters train to make them faster, stronger and more powerful athletes and how this training translates into the gym to people she coaches for body transformations looking for the ultimate lean physique. How did you train as a sprint athlete? I did long jump first. Then I switched to hurdles. So I was training six days a week for three or four hours a day. We had running sessions first – sprints on a track. Then we would have weights afterwards and then plyometrics after that. Monday, Wednesday, Friday, then intensity would be quite high. Then Tuesday and Thursday it would be lower because you can't train with such high intensity every single day because you would just breakdown and get injuries and things like that. So on a Monday we'd get to the track and warm up for an hour. Probably then do some sprint starts to the first hurdle or a long running session – that would be a good hour and a half. Then after that we would go into the gym and do a weights session as well. Then it would be a plyometrics session – so standing long jumps, box jumps, hurdle rebounds which is where you have five hurdles spread out and you would bound over them So explain the running element- what was the goal of the trainingat and what were the techniques involved? So the sprinting part it would be to either practice a certain movement over the hurdles – breaking the movement down into different sections. Or just to again practice a block start or a general conditioning session. During the winter we would do ten 300m runs with two or three minutes rest in between. Or we would have 30-second, 60-second and 90-second runs on the grass. We would also do 150m sprints where we'd do six of them. So it was pretty intense. The rests in between mean you can recover and go 100% again. But as the session goes on you get more tired but that's when you have to push more to build up the lactic tolerance. How does that training build up your lactic tolerance and how did it improve your performance? Because our event was speed endurance – even though it's a flat-out sprint there is endurance in there towards the end – because we're doing it over distance we're in a lactic state and we're trying to push your body through that, the body gets used to being in that state. So when it comes to a race we've already been in that condition already, so during a race it's easier for us to hold on and keep our form better. What kind of workwere you doing in the gym? We would probably do two gym sessions a week. Any more and we would have been a bit too heavy. We want to stay light but still be powerful and explosive. During the winter we would do heavier weights and more reps. So we would be doing cleans, squats and deadlifts. Then also doing isolation work on our hamstrings, quads and a lot of core work because of the position you have to hold going over a hurdle you need to be strong in your core. As it goes on through the season it would be lighter weights but quicker on the movements. Everything we did was quick, nothing was slow like you would normally do in the gym. We would be targeting different muscle fibres – we would always want to keep the fast twitch fibres conditioned. Did you find the gym work helped you become a better athlete? Yes it did, because we would do the gym where everything would be fast and explosive then you would come out and do plyometrics which correlated to what we were doing in the gym. You would feel bouncy and really fast. What kind of things were you doing with plyometrics and how did that improve your performance? We would do bunny hops over hurdles – so trying to make the least contact with the floor as possible. So we had to jump but as soon as you touch the floor you had to rebound and jump over the next hurdle, rather than sinking into the floor and going again. Because when we're sprinting we want our foot contact to be quite quick off the ground, so doing plyometrics where the contact is less on the floor, it really helps our sprinting. With the movement on the plyometrics it crosses over to sprinting. It gets the hip flexors involved as well. When you moved from athletics to what you do now, does a lot of it translate over? I was actually quite surprised by how different it is. With track and field everything is explosive and fast but with personal training you have to slow everything down so people can feel what muscles are moving and they can get the benefits of the weight training. The timings are obviously different as well – we would get a lot longer recovery because everything is so much more explosive. Whereas when someone is trying to get fit their recovery time is less. What elements from your athletics career benefit people who are looking to improve their body composition. It's all mental with a lot of people. They can push themselves to a certain limit, but they don't know how to get past that barrier. Whereas I know how to get them past that and get that extra little bit out of them. So being an athlete really helps with that. I tell them I've been through it and yes you're going to feel sick and feel bad in the hour, but afterwards you're going to feel really good. The weights they're using are getting heavier and they're getting stronger so it shows they are improving. What are the successful components to a good body transformation? Obviously a good diet – what they're eating is so important. Then in the gym it's a weights-based session followed by an interval session as well, so it raises their heart rate which carries over to the next day because their metabolism kicks up. The reps change throughout the transformation too. So we start around 12 reps then as each session goes on it drops down to 8-10s and then 6-8s as well. This is so the body doesn't plateau. It keeps your body on its toes, so to speak, so you don't get used to one way of training. People want to stay in their comfort zone but I have to try and push people out of that. Does some of your athlete training – particularly the spring interval work – carry over to helping people transform their physiques? Yes definitely. Especially the cardio at the end of the sessions. It's very beneficial. If you want a transformation and you want to lose fat, doing intervals will really help. It's because you're keeping the heart rate raised and keeping changing the interval durations. What are the things that are important to build muscle – things you've done as an athlete – that can be important for transformations. Definitely working on cycles for hypertrophy and using compound lifts as well. Recovery time [in between lifts] is key too. If you're just having one minute rest in between sets then you're not going to build any muscle. But if you're having two or three minutes in between each lift, then you will be doing enough damage to the muscle fibres in order for them to grow. If you're doing a more cardio-based workout (lower weight, higher reps) then you'll need less recovery. If you want to build muscle then just extend the time you're resting or recovering. We mainly use barbells and dumbbells work and focus on compound lifts. Then at the end do bodyweight circuits, rowing or bike intervals or sprinting as well. What is the best nutrition strategy for body composition then? Where I work, we have someone working specifically on nutrition. But the first 12 or 14 days they're off carbs – so just veg, good fats and protein. That shocks the body into using the fat stores as energy rather than storing it. Then after that they have a carb refeed so like sweet potato, oats or quinoa after a session. Then they only have carbs on the days they're at the gym. So it's carb cycling. It gets really good results – as long as people are sticking to it – and you can tell when they're not. But for the most part they do and they get really good results. It is almost the same as when I was an athlete. As a sprinter I didn't need that many carbs. Obviously I would have them on days that I was training. But if I was a long distance runner I would need more carbs for fuel. I was probably on about 2,000 calories a day – and the max was around 2,500. Some of the guys would be on more, but I always felt if I ate too much I felt too heavy. What key tips can people take from your time as an athlete to improve their health, their fitness or their body? Definitely do compound lifts in the gym. Also interval cardio rather than plodding along on a treadmill for 20 minutes because the heart rate goes up and down so you get more metabolic change rather than just being at one speed on a treadmill and you will get fitter quicker that way. Carb cycling is another big one – having a week off carbs and getting plenty of good fats like nuts and seeds. Then having a re-feed of good carbs like quinoa or oats. What exercise would it be to get the most benefit from? My favourite exercise is deadlift. It's a whole body workout. It literally works everything. Either trap bar deadlift or just a regular barbell, it's good to mix it up. Embody Fitness is an Olympic-standard personal training and body transformation studio in Bank, London. For more information please visit www.embodyfitness.co.uk Read more:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3XdcL4nVgWIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "af2e9378-1cba-4b05-927f-394aa32eb8ff"
      },
      "cell_type": "code",
      "source": [
        "# text=output['data']['text']\n",
        "# arr_text=extract_sentences_from_paragraph(text)\n",
        "# print(len(arr_text))\n",
        "# vec=make_array_vectorize(text)\n",
        "# print(vec.shape)\n",
        "# results=loaded_model.predict(vec)\n",
        "# for res in results:\n",
        "#   word_idx=sorted(range(len(res)), key=lambda i: res[i], reverse=True)[:15]\n",
        "#   for i in word_idx:\n",
        "#     res[i]=1\n",
        "# for res,sent in zip(results,arr_text):\n",
        "#   sent=str(make_text_35(sent))\n",
        "#   print(\" \".join([word for idx,word in enumerate(sent.split(\" \")) if(res[idx] == 1)]))\n",
        "# url='https://www.reuters.com/article/us-uber-ceo-idUSKBN19C0G6'\n",
        "# url='http://news.bbc.co.uk/2/hi/technology/4249437.stm'\n",
        "url='http://news.bbc.co.uk/2/hi/business/4236959.stm'\n",
        "# test_with_url(url)\n",
        "text_summary=test_with_url(url)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': {'title': '', 'text': 'Blockbusters like \\'Alexander\\' failed to conquer at the box office Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier. The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL. Mixed fortunes Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL\\'s underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL\\'s existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding. Film flops Time Warner\\'s fourth quarter profits were slightly better than analysts\\' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins. Restating revenues TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann\\'s purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.', 'images': {'0': None, '1': 'http://newsimg.bbc.co.uk/shared/img/o.gif', '3': 'http://stats.bbc.co.uk/o.gif?~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~4236959~RS~p~RS~0~RS~a~RS~International~RS~u~RS~/2/hi/business/4236959.stm~RS~r~RS~(none)~RS~q~RS~~RS~z~RS~06~RS~', '4': 'http://newsimg.bbc.co.uk/shared/img/toolbar_logo.gif', '5': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/bbc_logo.gif', '6': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/icons/video_text.gif', '7': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/icons/services_gen.gif', '8': 'http://news.bbcimg.co.uk/nol/shared/img/nav/v3_map_world_rb.gif', '11': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/dot_629.gif', '12': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/email.gif', '13': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/print.gif', '14': 'http://newsimg.bbc.co.uk/media/images/40796000/jpg/_40796749_alexanderap203.jpg', '16': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/start_quote_rb.gif', '17': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/end_quote_rb.gif', '18': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/inline_dashed_line.gif', '22': 'http://newsimg.bbc.co.uk/nol/shared/img/v3/line_seealso.gif', '26': 'http://news.bbc.co.uk///secure-uk.imrworldwide.com/cgi-bin/m?ci=bbc&amp;cg=0'}, 'publishingTime': False, 'language': 'en'}, 'result': 'success'}\n",
            "Blockbusters like 'Alexander' failed to conquer at the box office Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier. The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL. Mixed fortunes Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding. Film flops Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins. Restating revenues TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
            "20\n",
            "(20, 3500)\n",
            "blockbusters like alexander failed to conquer at box office quarterly profits us media giant timewarner\n",
            "the firm which is now one of the biggest investors in google benefited\n",
            "timewarner said fourth quarter sales rose to from\n",
            "its profits were buoyed by one off gains which offset a\n",
            "mixed fortunes time warner said on friday that it now\n",
            "but its own internet business aol had has mixed fortunes\n",
            "it lost subscribers in the fourth quarter profits were lower in the preceding quarters\n",
            "however the company said aol underlying profit before exceptional items rose on the back internet\n",
            "it hopes to increase subscribers by offering the online service to timewarner customers and will\n",
            "timewarner also has to restate and results following a probe by the securities exchange commission\n",
            "film flops time warner fourth quarter profits were slightly better than analysts expectations\n",
            "film profits slump helped box office alexander sharp contrast year earlier final film rings trilogy\n",
            "for the full year timewarner posted a profit of up from its performance while revenues\n",
            "our financial performance was strong meeting or exceeding all of our full year and greatly\n",
            "for timewarner is projecting operating earnings growth of around and also expects higher revenue\n",
            "restating revenues timewarner is to restate its accounts as part of efforts to resolve\n",
            "it has already offered to pay to settle that by\n",
            "the company said it was unable to estimate the amount it needed to which previously\n",
            "it intends to adjust the way it for a deal with german music publisher bertelsmann\n",
            "it will now book the sale of its stake in aol europe as a loss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dvAhIAV5gzmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "dd184470-b8a0-498d-8f7f-5fb151da3690"
      },
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/89/af359c22e1d858e0299d4cc9219f36b504817c9797acad23081247867845/rouge-0.3.1-py3-none-any.whl\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S1EBfC-0jxn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dea499b0-2dc0-4042-8429-6c574f68d380"
      },
      "cell_type": "code",
      "source": [
        "with open('bbc_pkl/texts.pkl', 'rb') as pickle_file:\n",
        "    source=pickle.load(pickle_file)\n",
        "with open('bbc_pkl/summary.pkl', 'rb') as pickle_file:\n",
        "    target=pickle.load(pickle_file)\n",
        "    \n",
        "print((source[0]))\n",
        "print(type(source[1]))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['quarterly profits at us media giant timewarner jumped to for the three months to december from year earlier', 'the firm which is now one of the biggest investors in google benefited from sales of high speed internet connections and higher advert sales', 'timewarner said fourth quarter sales rose to from', 'its profits were buoyed by one off gains which offset a profit dip at warner bros and less users for aol', 'time warner said on friday that it now owns of search engine google', 'but its own internet business aol had has mixed fortunes', 'it lost subscribers in the fourth quarter profits were lower than in the preceding three quarters', 'however the company said aol underlying profit before exceptional items rose on the back of stronger internet advertising revenues', 'it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aol existing customers for high speed broadband', 'timewarner also has to restate and results following a probe by the us securities exchange commission sec which is close to concluding', 'time warner fourth quarter profits were slightly better than analysts expectations', 'but its film division saw profits slump to helped by box office flops alexander and catwoman a sharp contrast to year earlier when the third and final film in the lord of the rings trilogy boosted results', 'for the full year timewarner posted a profit of up from its performance while revenues grew to', 'our financial performance was strong meeting or exceeding all of our full year objectives and greatly enhancing our flexibility chairman and chief executive richard parsons said', 'for timewarner is projecting operating earnings growth of around and also expects higher revenue and wider profit margins', 'timewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators', 'it has already offered to pay to settle charges in a deal that is under review by the sec', 'the company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at', 'it intends to adjust the way it accounts for a deal with german music publisher bertelsmann purchase of a stake in aol europe which it had reported as advertising revenue', 'it will now book the sale of its stake in aol europe as a loss on the value of that stake']\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zz46PxYYvXvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8a3b5e06-76f8-4218-c693-46f8c5d134c5"
      },
      "cell_type": "code",
      "source": [
        "import rouge\n",
        "evaluator = rouge.Rouge(metrics=['rouge-1','rouge-2'])\n",
        "scores = evaluator.get_scores(target[0], text_summary)\n",
        "print(scores)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'rouge-1': {'f': 0.5491803233539372, 'p': 0.7976190476190477, 'r': 0.41875}, 'rouge-2': {'f': 0.36723163395496194, 'p': 0.5462184873949579, 'r': 0.2765957446808511}}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "znCmRKIeAw3A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C3GAtZVVAxUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qY-cbfReAxP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ccb607de-86a9-4312-ba9b-f2ebcb9ab8f9"
      },
      "cell_type": "code",
      "source": [
        "print(source[:2])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['quarterly profits at us media giant timewarner jumped to for the three months to december from year earlier', 'the firm which is now one of the biggest investors in google benefited from sales of high speed internet connections and higher advert sales', 'timewarner said fourth quarter sales rose to from', 'its profits were buoyed by one off gains which offset a profit dip at warner bros and less users for aol', 'time warner said on friday that it now owns of search engine google', 'but its own internet business aol had has mixed fortunes', 'it lost subscribers in the fourth quarter profits were lower than in the preceding three quarters', 'however the company said aol underlying profit before exceptional items rose on the back of stronger internet advertising revenues', 'it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aol existing customers for high speed broadband', 'timewarner also has to restate and results following a probe by the us securities exchange commission sec which is close to concluding', 'time warner fourth quarter profits were slightly better than analysts expectations', 'but its film division saw profits slump to helped by box office flops alexander and catwoman a sharp contrast to year earlier when the third and final film in the lord of the rings trilogy boosted results', 'for the full year timewarner posted a profit of up from its performance while revenues grew to', 'our financial performance was strong meeting or exceeding all of our full year objectives and greatly enhancing our flexibility chairman and chief executive richard parsons said', 'for timewarner is projecting operating earnings growth of around and also expects higher revenue and wider profit margins', 'timewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators', 'it has already offered to pay to settle charges in a deal that is under review by the sec', 'the company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at', 'it intends to adjust the way it accounts for a deal with german music publisher bertelsmann purchase of a stake in aol europe which it had reported as advertising revenue', 'it will now book the sale of its stake in aol europe as a loss on the value of that stake'], ['the dollar has hit its highest level against the euro in almost three months after the federal reserve head said the us trade deficit is set to stabilise', 'and alan greenspan highlighted the us government willingness to curb spending and rising household savings as factors which may help to reduce it', 'in late trading in new york the dollar reached against the euro from on thursday', 'market concerns about the deficit has hit the greenback in recent months', 'on friday federal reserve chairman mr greenspan speech in london ahead of the meeting of g finance ministers sent the dollar higher after it had earlier tumbled on the back of worse than expected us jobs data', 'i think the chairman taking a much more sanguine view on the current account deficit than he taken for some time said robert sinche head of currency strategy at bank of america in new york', 'he taking a longer term view laying out a set of conditions under which the current account deficit can improve this year and next', 'worries about the deficit concerns about china do however remain', 'china currency remains pegged to the dollar and the us currency sharp falls in recent months have therefore made chinese export prices highly competitive', 'but calls for a shift in beijing policy have fallen on deaf ears despite recent comments in a major chinese newspaper that the time is ripe for a loosening of the peg', 'the g meeting is thought unlikely to produce any meaningful movement in chinese policy', 'in the meantime the us federal reserve decision on february to boost interest rates by a quarter of a point the sixth such move in as many months has opened up a differential with european rates', 'the half point window some believe could be enough to keep us assets looking more attractive and could help prop up the dollar', 'the recent falls have partly been the result of big budget deficits as well as the us yawning current account gap both of which need to be funded by the buying of us bonds and assets by foreign firms and governments', 'the white house will announce its budget on monday and many commentators believe the deficit will remain at close to half a trillion dollars']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v2UYalMaAxLw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_vectorize(texts):\n",
        "#   print(texts)\n",
        "#   print(len(texts))\n",
        "  nested_list_len = lambda x: sum(len(list) for list in x)\n",
        "  source_text_vectors = np.zeros((nested_list_len(texts), 3500))\n",
        "  vec_idx = 0\n",
        "  if(type(texts[0]) == list):\n",
        "      for i in range(len(texts)):\n",
        "          sentences = texts[i]\n",
        "          sentences_container = []\n",
        "          # Get text vector\n",
        "          for s in sentences:\n",
        "              sentence_vector = np.array([])\n",
        "              s=remove_stopwords(strip_punctuation(strip_non_alphanum(str(s).lower())))\n",
        "              s=clean_str(s)\n",
        "              for w in word_tokenize(s):\n",
        "                  w=lemmatizer.lemmatize(w)\n",
        "                  if(model_ft.__contains__(w)==False):\n",
        "                    continue\n",
        "                  if(len(sentence_vector) < MAX_SENTENCE_LEN*EMBEDDING_SIZE):\n",
        "                      sentence_vector = np.append(sentence_vector, model_ft[w])\n",
        "                  else:\n",
        "                      break\n",
        "              while(len(sentence_vector) < MAX_SENTENCE_LEN*EMBEDDING_SIZE):\n",
        "                  sentence_vector = np.append(sentence_vector,np.zeros(EMBEDDING_SIZE))\n",
        "              source_text_vectors[vec_idx] = sentence_vector\n",
        "              vec_idx+=1\n",
        "  return (source_text_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XOjS2EfKDl70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b5373bc4-a518-4462-aead-54eacb256de2"
      },
      "cell_type": "code",
      "source": [
        "print(test_vectorize(source[0]).shape)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['quarterly profits at us media giant timewarner jumped to for the three months to december from year earlier', 'the firm which is now one of the biggest investors in google benefited from sales of high speed internet connections and higher advert sales', 'timewarner said fourth quarter sales rose to from', 'its profits were buoyed by one off gains which offset a profit dip at warner bros and less users for aol', 'time warner said on friday that it now owns of search engine google', 'but its own internet business aol had has mixed fortunes', 'it lost subscribers in the fourth quarter profits were lower than in the preceding three quarters', 'however the company said aol underlying profit before exceptional items rose on the back of stronger internet advertising revenues', 'it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aol existing customers for high speed broadband', 'timewarner also has to restate and results following a probe by the us securities exchange commission sec which is close to concluding', 'time warner fourth quarter profits were slightly better than analysts expectations', 'but its film division saw profits slump to helped by box office flops alexander and catwoman a sharp contrast to year earlier when the third and final film in the lord of the rings trilogy boosted results', 'for the full year timewarner posted a profit of up from its performance while revenues grew to', 'our financial performance was strong meeting or exceeding all of our full year objectives and greatly enhancing our flexibility chairman and chief executive richard parsons said', 'for timewarner is projecting operating earnings growth of around and also expects higher revenue and wider profit margins', 'timewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators', 'it has already offered to pay to settle charges in a deal that is under review by the sec', 'the company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at', 'it intends to adjust the way it accounts for a deal with german music publisher bertelsmann purchase of a stake in aol europe which it had reported as advertising revenue', 'it will now book the sale of its stake in aol europe as a loss on the value of that stake']\n",
            "20\n",
            "(2316, 3500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ItS6gi-i0wc7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_rouge(text,org_sum_text):\n",
        "#   arr_text=extract_sentences_from_paragraph(text)\n",
        "  vec=test_vectorize(text)\n",
        "#   print(len(vec))\n",
        "  results=loaded_model.predict(vec)\n",
        "  for res in results:\n",
        "    word_idx=sorted(range(len(res)), key=lambda i: res[i], reverse=True)[:15]\n",
        "    for i in word_idx:\n",
        "      res[i]=1\n",
        "  sent_sum=' '\n",
        "  for res,sent in zip(results,text):\n",
        "    sent=str(make_text_35(sent))\n",
        "    s_indv=' '.join([word for idx,word in enumerate(sent.split(\" \")) if(res[idx] == 1)])\n",
        "    sent_sum=str(sent_sum)+str(s_indv)+str(',')\n",
        "#     print(s_indv)\n",
        "  #now computing rougue metric\n",
        "#   print(sent_sum)\n",
        "  evaluator = rouge.Rouge(metrics=['rouge-1','rouge-2'])\n",
        "  scores = evaluator.get_scores(org_sum_text, sent_sum)\n",
        "  return scores[0]['rouge-1']['f']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddDAAw1xBPpk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_rouge_dataset(source,target):\n",
        "  score=[]\n",
        "  for i in range(len(source)):\n",
        "    print(i)\n",
        "    score.append(find_rouge(source[i],target[i]))\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v-OBODiCHHnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37842
        },
        "outputId": "d2f3d4a3-a99a-4486-9a3a-de8ee18f6faa"
      },
      "cell_type": "code",
      "source": [
        "scores=find_rouge_dataset(source,target)\n",
        "#[{'rouge-1': {'f': 0.49107142388392866, 'p': 0.6547619047619048, 'r': 0.39285714285714285}, 'rouge-2': {'f': 0.24761904291781311, 'p': 0.3277310924369748, 'r': 0.1989795918367347}}]\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1258\n",
            "1259\n",
            "1260\n",
            "1261\n",
            "1262\n",
            "1263\n",
            "1264\n",
            "1265\n",
            "1266\n",
            "1267\n",
            "1268\n",
            "1269\n",
            "1270\n",
            "1271\n",
            "1272\n",
            "1273\n",
            "1274\n",
            "1275\n",
            "1276\n",
            "1277\n",
            "1278\n",
            "1279\n",
            "1280\n",
            "1281\n",
            "1282\n",
            "1283\n",
            "1284\n",
            "1285\n",
            "1286\n",
            "1287\n",
            "1288\n",
            "1289\n",
            "1290\n",
            "1291\n",
            "1292\n",
            "1293\n",
            "1294\n",
            "1295\n",
            "1296\n",
            "1297\n",
            "1298\n",
            "1299\n",
            "1300\n",
            "1301\n",
            "1302\n",
            "1303\n",
            "1304\n",
            "1305\n",
            "1306\n",
            "1307\n",
            "1308\n",
            "1309\n",
            "1310\n",
            "1311\n",
            "1312\n",
            "1313\n",
            "1314\n",
            "1315\n",
            "1316\n",
            "1317\n",
            "1318\n",
            "1319\n",
            "1320\n",
            "1321\n",
            "1322\n",
            "1323\n",
            "1324\n",
            "1325\n",
            "1326\n",
            "1327\n",
            "1328\n",
            "1329\n",
            "1330\n",
            "1331\n",
            "1332\n",
            "1333\n",
            "1334\n",
            "1335\n",
            "1336\n",
            "1337\n",
            "1338\n",
            "1339\n",
            "1340\n",
            "1341\n",
            "1342\n",
            "1343\n",
            "1344\n",
            "1345\n",
            "1346\n",
            "1347\n",
            "1348\n",
            "1349\n",
            "1350\n",
            "1351\n",
            "1352\n",
            "1353\n",
            "1354\n",
            "1355\n",
            "1356\n",
            "1357\n",
            "1358\n",
            "1359\n",
            "1360\n",
            "1361\n",
            "1362\n",
            "1363\n",
            "1364\n",
            "1365\n",
            "1366\n",
            "1367\n",
            "1368\n",
            "1369\n",
            "1370\n",
            "1371\n",
            "1372\n",
            "1373\n",
            "1374\n",
            "1375\n",
            "1376\n",
            "1377\n",
            "1378\n",
            "1379\n",
            "1380\n",
            "1381\n",
            "1382\n",
            "1383\n",
            "1384\n",
            "1385\n",
            "1386\n",
            "1387\n",
            "1388\n",
            "1389\n",
            "1390\n",
            "1391\n",
            "1392\n",
            "1393\n",
            "1394\n",
            "1395\n",
            "1396\n",
            "1397\n",
            "1398\n",
            "1399\n",
            "1400\n",
            "1401\n",
            "1402\n",
            "1403\n",
            "1404\n",
            "1405\n",
            "1406\n",
            "1407\n",
            "1408\n",
            "1409\n",
            "1410\n",
            "1411\n",
            "1412\n",
            "1413\n",
            "1414\n",
            "1415\n",
            "1416\n",
            "1417\n",
            "1418\n",
            "1419\n",
            "1420\n",
            "1421\n",
            "1422\n",
            "1423\n",
            "1424\n",
            "1425\n",
            "1426\n",
            "1427\n",
            "1428\n",
            "1429\n",
            "1430\n",
            "1431\n",
            "1432\n",
            "1433\n",
            "1434\n",
            "1435\n",
            "1436\n",
            "1437\n",
            "1438\n",
            "1439\n",
            "1440\n",
            "1441\n",
            "1442\n",
            "1443\n",
            "1444\n",
            "1445\n",
            "1446\n",
            "1447\n",
            "1448\n",
            "1449\n",
            "1450\n",
            "1451\n",
            "1452\n",
            "1453\n",
            "1454\n",
            "1455\n",
            "1456\n",
            "1457\n",
            "1458\n",
            "1459\n",
            "1460\n",
            "1461\n",
            "1462\n",
            "1463\n",
            "1464\n",
            "1465\n",
            "1466\n",
            "1467\n",
            "1468\n",
            "1469\n",
            "1470\n",
            "1471\n",
            "1472\n",
            "1473\n",
            "1474\n",
            "1475\n",
            "1476\n",
            "1477\n",
            "1478\n",
            "1479\n",
            "1480\n",
            "1481\n",
            "1482\n",
            "1483\n",
            "1484\n",
            "1485\n",
            "1486\n",
            "1487\n",
            "1488\n",
            "1489\n",
            "1490\n",
            "1491\n",
            "1492\n",
            "1493\n",
            "1494\n",
            "1495\n",
            "1496\n",
            "1497\n",
            "1498\n",
            "1499\n",
            "1500\n",
            "1501\n",
            "1502\n",
            "1503\n",
            "1504\n",
            "1505\n",
            "1506\n",
            "1507\n",
            "1508\n",
            "1509\n",
            "1510\n",
            "1511\n",
            "1512\n",
            "1513\n",
            "1514\n",
            "1515\n",
            "1516\n",
            "1517\n",
            "1518\n",
            "1519\n",
            "1520\n",
            "1521\n",
            "1522\n",
            "1523\n",
            "1524\n",
            "1525\n",
            "1526\n",
            "1527\n",
            "1528\n",
            "1529\n",
            "1530\n",
            "1531\n",
            "1532\n",
            "1533\n",
            "1534\n",
            "1535\n",
            "1536\n",
            "1537\n",
            "1538\n",
            "1539\n",
            "1540\n",
            "1541\n",
            "1542\n",
            "1543\n",
            "1544\n",
            "1545\n",
            "1546\n",
            "1547\n",
            "1548\n",
            "1549\n",
            "1550\n",
            "1551\n",
            "1552\n",
            "1553\n",
            "1554\n",
            "1555\n",
            "1556\n",
            "1557\n",
            "1558\n",
            "1559\n",
            "1560\n",
            "1561\n",
            "1562\n",
            "1563\n",
            "1564\n",
            "1565\n",
            "1566\n",
            "1567\n",
            "1568\n",
            "1569\n",
            "1570\n",
            "1571\n",
            "1572\n",
            "1573\n",
            "1574\n",
            "1575\n",
            "1576\n",
            "1577\n",
            "1578\n",
            "1579\n",
            "1580\n",
            "1581\n",
            "1582\n",
            "1583\n",
            "1584\n",
            "1585\n",
            "1586\n",
            "1587\n",
            "1588\n",
            "1589\n",
            "1590\n",
            "1591\n",
            "1592\n",
            "1593\n",
            "1594\n",
            "1595\n",
            "1596\n",
            "1597\n",
            "1598\n",
            "1599\n",
            "1600\n",
            "1601\n",
            "1602\n",
            "1603\n",
            "1604\n",
            "1605\n",
            "1606\n",
            "1607\n",
            "1608\n",
            "1609\n",
            "1610\n",
            "1611\n",
            "1612\n",
            "1613\n",
            "1614\n",
            "1615\n",
            "1616\n",
            "1617\n",
            "1618\n",
            "1619\n",
            "1620\n",
            "1621\n",
            "1622\n",
            "1623\n",
            "1624\n",
            "1625\n",
            "1626\n",
            "1627\n",
            "1628\n",
            "1629\n",
            "1630\n",
            "1631\n",
            "1632\n",
            "1633\n",
            "1634\n",
            "1635\n",
            "1636\n",
            "1637\n",
            "1638\n",
            "1639\n",
            "1640\n",
            "1641\n",
            "1642\n",
            "1643\n",
            "1644\n",
            "1645\n",
            "1646\n",
            "1647\n",
            "1648\n",
            "1649\n",
            "1650\n",
            "1651\n",
            "1652\n",
            "1653\n",
            "1654\n",
            "1655\n",
            "1656\n",
            "1657\n",
            "1658\n",
            "1659\n",
            "1660\n",
            "1661\n",
            "1662\n",
            "1663\n",
            "1664\n",
            "1665\n",
            "1666\n",
            "1667\n",
            "1668\n",
            "1669\n",
            "1670\n",
            "1671\n",
            "1672\n",
            "1673\n",
            "1674\n",
            "1675\n",
            "1676\n",
            "1677\n",
            "1678\n",
            "1679\n",
            "1680\n",
            "1681\n",
            "1682\n",
            "1683\n",
            "1684\n",
            "1685\n",
            "1686\n",
            "1687\n",
            "1688\n",
            "1689\n",
            "1690\n",
            "1691\n",
            "1692\n",
            "1693\n",
            "1694\n",
            "1695\n",
            "1696\n",
            "1697\n",
            "1698\n",
            "1699\n",
            "1700\n",
            "1701\n",
            "1702\n",
            "1703\n",
            "1704\n",
            "1705\n",
            "1706\n",
            "1707\n",
            "1708\n",
            "1709\n",
            "1710\n",
            "1711\n",
            "1712\n",
            "1713\n",
            "1714\n",
            "1715\n",
            "1716\n",
            "1717\n",
            "1718\n",
            "1719\n",
            "1720\n",
            "1721\n",
            "1722\n",
            "1723\n",
            "1724\n",
            "1725\n",
            "1726\n",
            "1727\n",
            "1728\n",
            "1729\n",
            "1730\n",
            "1731\n",
            "1732\n",
            "1733\n",
            "1734\n",
            "1735\n",
            "1736\n",
            "1737\n",
            "1738\n",
            "1739\n",
            "1740\n",
            "1741\n",
            "1742\n",
            "1743\n",
            "1744\n",
            "1745\n",
            "1746\n",
            "1747\n",
            "1748\n",
            "1749\n",
            "1750\n",
            "1751\n",
            "1752\n",
            "1753\n",
            "1754\n",
            "1755\n",
            "1756\n",
            "1757\n",
            "1758\n",
            "1759\n",
            "1760\n",
            "1761\n",
            "1762\n",
            "1763\n",
            "1764\n",
            "1765\n",
            "1766\n",
            "1767\n",
            "1768\n",
            "1769\n",
            "1770\n",
            "1771\n",
            "1772\n",
            "1773\n",
            "1774\n",
            "1775\n",
            "1776\n",
            "1777\n",
            "1778\n",
            "1779\n",
            "1780\n",
            "1781\n",
            "1782\n",
            "1783\n",
            "1784\n",
            "1785\n",
            "1786\n",
            "1787\n",
            "1788\n",
            "1789\n",
            "1790\n",
            "1791\n",
            "1792\n",
            "1793\n",
            "1794\n",
            "1795\n",
            "1796\n",
            "1797\n",
            "1798\n",
            "1799\n",
            "1800\n",
            "1801\n",
            "1802\n",
            "1803\n",
            "1804\n",
            "1805\n",
            "1806\n",
            "1807\n",
            "1808\n",
            "1809\n",
            "1810\n",
            "1811\n",
            "1812\n",
            "1813\n",
            "1814\n",
            "1815\n",
            "1816\n",
            "1817\n",
            "1818\n",
            "1819\n",
            "1820\n",
            "1821\n",
            "1822\n",
            "1823\n",
            "1824\n",
            "1825\n",
            "1826\n",
            "1827\n",
            "1828\n",
            "1829\n",
            "1830\n",
            "1831\n",
            "1832\n",
            "1833\n",
            "1834\n",
            "1835\n",
            "1836\n",
            "1837\n",
            "1838\n",
            "1839\n",
            "1840\n",
            "1841\n",
            "1842\n",
            "1843\n",
            "1844\n",
            "1845\n",
            "1846\n",
            "1847\n",
            "1848\n",
            "1849\n",
            "1850\n",
            "1851\n",
            "1852\n",
            "1853\n",
            "1854\n",
            "1855\n",
            "1856\n",
            "1857\n",
            "1858\n",
            "1859\n",
            "1860\n",
            "1861\n",
            "1862\n",
            "1863\n",
            "1864\n",
            "1865\n",
            "1866\n",
            "1867\n",
            "1868\n",
            "1869\n",
            "1870\n",
            "1871\n",
            "1872\n",
            "1873\n",
            "1874\n",
            "1875\n",
            "1876\n",
            "1877\n",
            "1878\n",
            "1879\n",
            "1880\n",
            "1881\n",
            "1882\n",
            "1883\n",
            "1884\n",
            "1885\n",
            "1886\n",
            "1887\n",
            "1888\n",
            "1889\n",
            "1890\n",
            "1891\n",
            "1892\n",
            "1893\n",
            "1894\n",
            "1895\n",
            "1896\n",
            "1897\n",
            "1898\n",
            "1899\n",
            "1900\n",
            "1901\n",
            "1902\n",
            "1903\n",
            "1904\n",
            "1905\n",
            "1906\n",
            "1907\n",
            "1908\n",
            "1909\n",
            "1910\n",
            "1911\n",
            "1912\n",
            "1913\n",
            "1914\n",
            "1915\n",
            "1916\n",
            "1917\n",
            "1918\n",
            "1919\n",
            "1920\n",
            "1921\n",
            "1922\n",
            "1923\n",
            "1924\n",
            "1925\n",
            "1926\n",
            "1927\n",
            "1928\n",
            "1929\n",
            "1930\n",
            "1931\n",
            "1932\n",
            "1933\n",
            "1934\n",
            "1935\n",
            "1936\n",
            "1937\n",
            "1938\n",
            "1939\n",
            "1940\n",
            "1941\n",
            "1942\n",
            "1943\n",
            "1944\n",
            "1945\n",
            "1946\n",
            "1947\n",
            "1948\n",
            "1949\n",
            "1950\n",
            "1951\n",
            "1952\n",
            "1953\n",
            "1954\n",
            "1955\n",
            "1956\n",
            "1957\n",
            "1958\n",
            "1959\n",
            "1960\n",
            "1961\n",
            "1962\n",
            "1963\n",
            "1964\n",
            "1965\n",
            "1966\n",
            "1967\n",
            "1968\n",
            "1969\n",
            "1970\n",
            "1971\n",
            "1972\n",
            "1973\n",
            "1974\n",
            "1975\n",
            "1976\n",
            "1977\n",
            "1978\n",
            "1979\n",
            "1980\n",
            "1981\n",
            "1982\n",
            "1983\n",
            "1984\n",
            "1985\n",
            "1986\n",
            "1987\n",
            "1988\n",
            "1989\n",
            "1990\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n",
            "2021\n",
            "2022\n",
            "2023\n",
            "2024\n",
            "2025\n",
            "2026\n",
            "2027\n",
            "2028\n",
            "2029\n",
            "2030\n",
            "2031\n",
            "2032\n",
            "2033\n",
            "2034\n",
            "2035\n",
            "2036\n",
            "2037\n",
            "2038\n",
            "2039\n",
            "2040\n",
            "2041\n",
            "2042\n",
            "2043\n",
            "2044\n",
            "2045\n",
            "2046\n",
            "2047\n",
            "2048\n",
            "2049\n",
            "2050\n",
            "2051\n",
            "2052\n",
            "2053\n",
            "2054\n",
            "2055\n",
            "2056\n",
            "2057\n",
            "2058\n",
            "2059\n",
            "2060\n",
            "2061\n",
            "2062\n",
            "2063\n",
            "2064\n",
            "2065\n",
            "2066\n",
            "2067\n",
            "2068\n",
            "2069\n",
            "2070\n",
            "2071\n",
            "2072\n",
            "2073\n",
            "2074\n",
            "2075\n",
            "2076\n",
            "2077\n",
            "2078\n",
            "2079\n",
            "2080\n",
            "2081\n",
            "2082\n",
            "2083\n",
            "2084\n",
            "2085\n",
            "2086\n",
            "2087\n",
            "2088\n",
            "2089\n",
            "2090\n",
            "2091\n",
            "2092\n",
            "2093\n",
            "2094\n",
            "2095\n",
            "2096\n",
            "2097\n",
            "2098\n",
            "2099\n",
            "2100\n",
            "2101\n",
            "2102\n",
            "2103\n",
            "2104\n",
            "2105\n",
            "2106\n",
            "2107\n",
            "2108\n",
            "2109\n",
            "2110\n",
            "2111\n",
            "2112\n",
            "2113\n",
            "2114\n",
            "2115\n",
            "2116\n",
            "2117\n",
            "2118\n",
            "2119\n",
            "2120\n",
            "2121\n",
            "2122\n",
            "2123\n",
            "2124\n",
            "2125\n",
            "2126\n",
            "2127\n",
            "2128\n",
            "2129\n",
            "2130\n",
            "2131\n",
            "2132\n",
            "2133\n",
            "2134\n",
            "2135\n",
            "2136\n",
            "2137\n",
            "2138\n",
            "2139\n",
            "2140\n",
            "2141\n",
            "2142\n",
            "2143\n",
            "2144\n",
            "2145\n",
            "2146\n",
            "2147\n",
            "2148\n",
            "2149\n",
            "2150\n",
            "2151\n",
            "2152\n",
            "2153\n",
            "2154\n",
            "2155\n",
            "2156\n",
            "2157\n",
            "2158\n",
            "2159\n",
            "2160\n",
            "2161\n",
            "2162\n",
            "2163\n",
            "2164\n",
            "2165\n",
            "2166\n",
            "2167\n",
            "2168\n",
            "2169\n",
            "2170\n",
            "2171\n",
            "2172\n",
            "2173\n",
            "2174\n",
            "2175\n",
            "2176\n",
            "2177\n",
            "2178\n",
            "2179\n",
            "2180\n",
            "2181\n",
            "2182\n",
            "2183\n",
            "2184\n",
            "2185\n",
            "2186\n",
            "2187\n",
            "2188\n",
            "2189\n",
            "2190\n",
            "2191\n",
            "2192\n",
            "2193\n",
            "2194\n",
            "2195\n",
            "2196\n",
            "2197\n",
            "2198\n",
            "2199\n",
            "2200\n",
            "2201\n",
            "2202\n",
            "2203\n",
            "2204\n",
            "2205\n",
            "2206\n",
            "2207\n",
            "2208\n",
            "2209\n",
            "2210\n",
            "2211\n",
            "2212\n",
            "2213\n",
            "2214\n",
            "2215\n",
            "2216\n",
            "2217\n",
            "2218\n",
            "2219\n",
            "2220\n",
            "2221\n",
            "2222\n",
            "2223\n",
            "2224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l--ua64cJlO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "387f3282-4884-46ff-ca9e-18aa50158a47"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import statistics as st\n",
        "print(max(scores),st.mean(scores),st.stdev(scores),min(scores),len(scores))\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6966292084949993 0.5532263470885768 0.04438536530310459 0.1999999980246914 2225\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}