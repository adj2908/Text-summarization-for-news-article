{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_bbc.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K2-2dARxunjH",
        "colab_type": "code",
        "outputId": "173515bc-b3f0-4428-fcce-8fd9df78c723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import nltk\n",
        "import pickle\n",
        "import random\n",
        "import argparse\n",
        "import csv\n",
        "import os\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from gensim.models import FastText,Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, strip_non_alphanum\n",
        "import nltk\n",
        "from nltk import sent_tokenize,word_tokenize\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import model_from_json\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tygoR30guvgS",
        "colab_type": "code",
        "outputId": "dd04254b-ec62-45ec-b8f4-efbb30a7f824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')  \n",
        "for file in os.listdir('.'):\n",
        "  print(file)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Untitled0.ipynb\n",
            "Word2Vec.ipynb\n",
            "vector_avg.ipynb\n",
            "Doc2Vec.ipynb\n",
            "news_cleaned_combined_ctext.txt\n",
            "vector.pkl\n",
            "newsCleaned_final.txt\n",
            "news_cleaned_combined_ctext_final.txt\n",
            "vector_summary.ipynb\n",
            "text_token.txt\n",
            "word2vec.model\n",
            "newsCleaned_ctxt.txt\n",
            "newsCleaned.txt\n",
            "bbc_pkl\n",
            "bbc_ft.bin\n",
            "model.ipynb\n",
            "Untitled1.ipynb\n",
            "bbc_short_sum_pkl\n",
            "models\n",
            "vector_text.ipynb\n",
            "model_bbc_short_summary.ipynb\n",
            "Untitled2.ipynb\n",
            "weights_satisfied.hdf5\n",
            "outputs.npy\n",
            "inputs.npy\n",
            "model.json\n",
            "model.h5\n",
            "model_test.ipynb\n",
            "model_bbc.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J7501G8yuy6g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "allWords = []\n",
        "MAX_SENTENCE_LEN = 35\n",
        "EMBEDDING_SIZE = 100\n",
        "# p is the index into our training data for where we are now.\n",
        "p = 0\n",
        "accuracy_print_interval = 5\n",
        "# number of neurons in each layer\n",
        "input_num_units = MAX_SENTENCE_LEN*EMBEDDING_SIZE\n",
        "hidden_num_units = 1500\n",
        "output_num_units = MAX_SENTENCE_LEN\n",
        "epochs = 250\n",
        "batch_size = 32\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WHys8igyJYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_ft = FastText.load('bbc_ft.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGCNf7J1G78o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_str(string):\n",
        "    string = re.sub(r\"\\'s\", \"\", string)\n",
        "    string = re.sub(r\"\\'ve\", \"\", string)\n",
        "    string = re.sub(r\"n\\'t\", \"\", string)\n",
        "    string = re.sub(r\"\\'re\", \"\", string)\n",
        "    string = re.sub(r\"\\'d\", \"\", string)\n",
        "    string = re.sub(r\"\\'ll\", \"\", string)\n",
        "    string = re.sub(r\",\", \"\", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \"\", string)\n",
        "    string = re.sub(r\"\\)\", \"\", string)\n",
        "    string = re.sub(r\"\\?\", \"\", string)\n",
        "    string = re.sub(r\"'\", \"\", string)\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"[0-9]\\w+|[0-9]\",\"\", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = re.sub(r\"\\n\",'',string)\n",
        "    string = re.sub(r\"  \",\" \",string)\n",
        "    return string.strip().lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GDGUzPOuu9q9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vectorize_texts_and_summaries(texts, summaries):\n",
        "    ct=0\n",
        "    global MAX_SENTENCE_LEN\n",
        "    nested_list_len = lambda x: sum(len(list) for list in x)\n",
        "    t_vectors = []\n",
        "    source_text_vectors = np.zeros((nested_list_len(texts), MAX_SENTENCE_LEN*EMBEDDING_SIZE))\n",
        "    s_vectors = []\n",
        "    target_summary_vectors = np.zeros((nested_list_len(texts), MAX_SENTENCE_LEN))\n",
        "    vec_idx = 0\n",
        "    not_vocab=[]\n",
        "    if(type(texts[0]) == list):\n",
        "        for i in range(len(texts)):\n",
        "            summary = summaries[i]\n",
        "            sentences = texts[i]\n",
        "            sentences_container = []\n",
        "            # Get text vector\n",
        "            for s in sentences:\n",
        "                sentence_vector = np.array([])\n",
        "                target_vector = np.array([])\n",
        "                s=remove_stopwords(strip_punctuation(strip_non_alphanum(str(s).lower())))\n",
        "                s=clean_str(s)\n",
        "                for w in word_tokenize(s):\n",
        "                    if(model_ft.__contains__(w)==False):\n",
        "                      print(w)\n",
        "                      continue\n",
        "                    if(len(sentence_vector) < MAX_SENTENCE_LEN*EMBEDDING_SIZE):\n",
        "                        sentence_vector = np.append(sentence_vector, model_ft[w])\n",
        "                        target_vector = np.append(target_vector, int(w in summary))\n",
        "                    else:\n",
        "                        break\n",
        "                while(len(sentence_vector) < MAX_SENTENCE_LEN*EMBEDDING_SIZE):\n",
        "                    sentence_vector = np.append(sentence_vector,np.zeros(EMBEDDING_SIZE))\n",
        "                    target_vector = np.append(target_vector, 0)\n",
        "                source_text_vectors[vec_idx] = sentence_vector\n",
        "                target_summary_vectors[vec_idx] = target_vector\n",
        "                vec_idx+=1\n",
        "    return (source_text_vectors, target_summary_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B7gXiS8WwheQ",
        "colab_type": "code",
        "outputId": "bb90854d-64da-4496-e795-d3f8f402f56d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('bbc_pkl/texts.pkl', 'rb') as pickle_file:\n",
        "    source=pickle.load(pickle_file)\n",
        "with open('bbc_pkl/summary.pkl', 'rb') as pickle_file:\n",
        "    target=pickle.load(pickle_file)\n",
        "    \n",
        "print(len(source))\n",
        "print(len(target))\n",
        "print(source[0])\n",
        "print(target[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2225\n",
            "2225\n",
            "['quarterly profits at us media giant timewarner jumped to for the three months to december from year earlier', 'the firm which is now one of the biggest investors in google benefited from sales of high speed internet connections and higher advert sales', 'timewarner said fourth quarter sales rose to from', 'its profits were buoyed by one off gains which offset a profit dip at warner bros and less users for aol', 'time warner said on friday that it now owns of search engine google', 'but its own internet business aol had has mixed fortunes', 'it lost subscribers in the fourth quarter profits were lower than in the preceding three quarters', 'however the company said aol underlying profit before exceptional items rose on the back of stronger internet advertising revenues', 'it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aol existing customers for high speed broadband', 'timewarner also has to restate and results following a probe by the us securities exchange commission sec which is close to concluding', 'time warner fourth quarter profits were slightly better than analysts expectations', 'but its film division saw profits slump to helped by box office flops alexander and catwoman a sharp contrast to year earlier when the third and final film in the lord of the rings trilogy boosted results', 'for the full year timewarner posted a profit of up from its performance while revenues grew to', 'our financial performance was strong meeting or exceeding all of our full year objectives and greatly enhancing our flexibility chairman and chief executive richard parsons said', 'for timewarner is projecting operating earnings growth of around and also expects higher revenue and wider profit margins', 'timewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators', 'it has already offered to pay to settle charges in a deal that is under review by the sec', 'the company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at', 'it intends to adjust the way it accounts for a deal with german music publisher bertelsmann purchase of a stake in aol europe which it had reported as advertising revenue', 'it will now book the sale of its stake in aol europe as a loss on the value of that stake']\n",
            "timewarner said fourth quarter sales rose to from for the full year timewarner posted a profit of up from its performance while revenues grew to quarterly profits at us media giant timewarner jumped to for the three months to december from year earlier however the company said aol underlying profit before exceptional items rose on the back of stronger internet advertising revenues its profits were buoyed by one off gains which offset a profit dip at warner bros and less users for aol for timewarner is projecting operating earnings growth of around and also expects higher revenue and wider profit margins it lost subscribers in the fourth quarter profits were lower than in the preceding three quarters time warner fourth quarter profits were slightly better than analysts expectations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xtIu7Yv_x5Pc",
        "colab_type": "code",
        "outputId": "7948b733-7c04-426a-c1f6-e62ba40a321f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1499
        }
      },
      "cell_type": "code",
      "source": [
        "source_vec,target_vec=vectorize_texts_and_summaries(source,target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rj\n",
            "xlr\n",
            "dz\n",
            "dhl\n",
            "rj\n",
            "cfd\n",
            "cfd\n",
            "cfd\n",
            "pwc\n",
            "ccf\n",
            "kk\n",
            "hk\n",
            "hk\n",
            "zdf\n",
            "rj\n",
            "rj\n",
            "jd\n",
            "jd\n",
            "lr\n",
            "kk\n",
            "pwc\n",
            "pwc\n",
            "pwc\n",
            "jm\n",
            "jm\n",
            "jfk\n",
            "dmx\n",
            "pj\n",
            "vs\n",
            "jj\n",
            "nx\n",
            "rdf\n",
            "rdf\n",
            "nrj\n",
            "nrj\n",
            "vp\n",
            "pj\n",
            "pj\n",
            "xxl\n",
            "jm\n",
            "jm\n",
            "cfx\n",
            "cfx\n",
            "bwv\n",
            "vs\n",
            "hq\n",
            "hq\n",
            "www\n",
            "ldv\n",
            "fh\n",
            "kp\n",
            "lw\n",
            "kp\n",
            "lw\n",
            "kp\n",
            "kp\n",
            "qv\n",
            "ql\n",
            "www\n",
            "yh\n",
            "jf\n",
            "vj\n",
            "vj\n",
            "hl\n",
            "hl\n",
            "sd\n",
            "sd\n",
            "sd\n",
            "wcg\n",
            "wcg\n",
            "cvs\n",
            "jvc\n",
            "jvc\n",
            "cvs\n",
            "sd\n",
            "www\n",
            "yh\n",
            "gfk\n",
            "vj\n",
            "qv\n",
            "ql\n",
            "wltm\n",
            "tdg\n",
            "lzw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "No3VO08vzqFX",
        "colab_type": "code",
        "outputId": "e6465e3a-1f73-435d-ff37-16b1ec03155b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# SAVE\n",
        "np.save('inputs.npy', source_vec, allow_pickle=False)\n",
        "np.save('outputs.npy', target_vec, allow_pickle=False)\n",
        "# LOAD\n",
        "# source_vec = np.load('inputs.npy')\n",
        "# target_vec = np.load('outputs.npy')\n",
        "print(len(source_vec),len(target_vec))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41403 41403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DWHNPAdU4mft",
        "colab_type": "code",
        "outputId": "b9f40882-539d-404a-8041-bf1570fc12ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1500, input_dim=3500, activation='relu'))\n",
        "model.add(Dense(35, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1500)              5251500   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 35)                52535     \n",
            "=================================================================\n",
            "Total params: 5,304,035\n",
            "Trainable params: 5,304,035\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NcWVm5yD5Gw2",
        "colab_type": "code",
        "outputId": "519318e1-c32d-4db1-da67-61649c9455bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3505
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(source_vec, target_vec, epochs=100, batch_size=32,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "41403/41403 [==============================] - 15s 353us/step - loss: 15.8458\n",
            "Epoch 2/100\n",
            "41403/41403 [==============================] - 13s 321us/step - loss: 15.6566\n",
            "Epoch 3/100\n",
            "41403/41403 [==============================] - 14s 331us/step - loss: 15.6183\n",
            "Epoch 4/100\n",
            "41403/41403 [==============================] - 13s 323us/step - loss: 15.5689\n",
            "Epoch 5/100\n",
            "41403/41403 [==============================] - 13s 321us/step - loss: 15.4926\n",
            "Epoch 6/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 15.3985\n",
            "Epoch 7/100\n",
            "41403/41403 [==============================] - 13s 324us/step - loss: 15.2981\n",
            "Epoch 8/100\n",
            "41403/41403 [==============================] - 13s 323us/step - loss: 15.1981\n",
            "Epoch 9/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 15.1116\n",
            "Epoch 10/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 15.0341\n",
            "Epoch 11/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.9637\n",
            "Epoch 12/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.9083\n",
            "Epoch 13/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.8571\n",
            "Epoch 14/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.8111\n",
            "Epoch 15/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.7791\n",
            "Epoch 16/100\n",
            "41403/41403 [==============================] - 13s 316us/step - loss: 14.7451\n",
            "Epoch 17/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.7161\n",
            "Epoch 18/100\n",
            "41403/41403 [==============================] - 13s 320us/step - loss: 14.6871\n",
            "Epoch 19/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.6627\n",
            "Epoch 20/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.6420\n",
            "Epoch 21/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.6169\n",
            "Epoch 22/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.6055\n",
            "Epoch 23/100\n",
            "41403/41403 [==============================] - 13s 316us/step - loss: 14.5878\n",
            "Epoch 24/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.5661\n",
            "Epoch 25/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.5585\n",
            "Epoch 26/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.5463\n",
            "Epoch 27/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.5290\n",
            "Epoch 28/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.5198\n",
            "Epoch 29/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.5107\n",
            "Epoch 30/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.5011\n",
            "Epoch 31/100\n",
            "41403/41403 [==============================] - 14s 328us/step - loss: 14.4881\n",
            "Epoch 32/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.4752\n",
            "Epoch 33/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.4743\n",
            "Epoch 34/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.4629\n",
            "Epoch 35/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.4523\n",
            "Epoch 36/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.4489\n",
            "Epoch 37/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.4418\n",
            "Epoch 38/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.4371\n",
            "Epoch 39/100\n",
            "41403/41403 [==============================] - 13s 324us/step - loss: 14.4238\n",
            "Epoch 40/100\n",
            "41403/41403 [==============================] - 14s 328us/step - loss: 14.4170\n",
            "Epoch 41/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.4207\n",
            "Epoch 42/100\n",
            "41403/41403 [==============================] - 14s 326us/step - loss: 14.4078\n",
            "Epoch 43/100\n",
            "41403/41403 [==============================] - 14s 328us/step - loss: 14.4023\n",
            "Epoch 44/100\n",
            "41403/41403 [==============================] - 13s 326us/step - loss: 14.3985\n",
            "Epoch 45/100\n",
            "41403/41403 [==============================] - 13s 324us/step - loss: 14.3971\n",
            "Epoch 46/100\n",
            "41403/41403 [==============================] - 14s 328us/step - loss: 14.3879\n",
            "Epoch 47/100\n",
            "41403/41403 [==============================] - 13s 325us/step - loss: 14.3824\n",
            "Epoch 48/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.3764\n",
            "Epoch 49/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.3728\n",
            "Epoch 50/100\n",
            "41403/41403 [==============================] - 13s 320us/step - loss: 14.3767\n",
            "Epoch 51/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.3662\n",
            "Epoch 52/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.3628\n",
            "Epoch 53/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.3596\n",
            "Epoch 54/100\n",
            "41403/41403 [==============================] - 14s 327us/step - loss: 14.3577\n",
            "Epoch 55/100\n",
            "41403/41403 [==============================] - 13s 323us/step - loss: 14.3495\n",
            "Epoch 56/100\n",
            "41403/41403 [==============================] - 14s 327us/step - loss: 14.3492\n",
            "Epoch 57/100\n",
            "41403/41403 [==============================] - 14s 327us/step - loss: 14.3437\n",
            "Epoch 58/100\n",
            "41403/41403 [==============================] - 13s 320us/step - loss: 14.3419\n",
            "Epoch 59/100\n",
            "41403/41403 [==============================] - 13s 325us/step - loss: 14.3405\n",
            "Epoch 60/100\n",
            "41403/41403 [==============================] - 13s 322us/step - loss: 14.3370\n",
            "Epoch 61/100\n",
            "41403/41403 [==============================] - 13s 324us/step - loss: 14.3304\n",
            "Epoch 62/100\n",
            "41403/41403 [==============================] - 13s 325us/step - loss: 14.3338\n",
            "Epoch 63/100\n",
            "41403/41403 [==============================] - 13s 326us/step - loss: 14.3338\n",
            "Epoch 64/100\n",
            "41403/41403 [==============================] - 14s 331us/step - loss: 14.3226\n",
            "Epoch 65/100\n",
            "41403/41403 [==============================] - 14s 327us/step - loss: 14.3265\n",
            "Epoch 66/100\n",
            "41403/41403 [==============================] - 14s 328us/step - loss: 14.3190\n",
            "Epoch 67/100\n",
            "41403/41403 [==============================] - 13s 321us/step - loss: 14.3172\n",
            "Epoch 68/100\n",
            "41403/41403 [==============================] - 13s 320us/step - loss: 14.3147\n",
            "Epoch 69/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.3154\n",
            "Epoch 70/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.3106\n",
            "Epoch 71/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.3064\n",
            "Epoch 72/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.3051\n",
            "Epoch 73/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.3046\n",
            "Epoch 74/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.3027\n",
            "Epoch 75/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.3000\n",
            "Epoch 76/100\n",
            "41403/41403 [==============================] - 13s 321us/step - loss: 14.2984\n",
            "Epoch 77/100\n",
            "41403/41403 [==============================] - 13s 324us/step - loss: 14.2972\n",
            "Epoch 78/100\n",
            "41403/41403 [==============================] - 13s 323us/step - loss: 14.2952\n",
            "Epoch 79/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.2925\n",
            "Epoch 80/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.2928\n",
            "Epoch 81/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.2863\n",
            "Epoch 82/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.2875\n",
            "Epoch 83/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.2902\n",
            "Epoch 84/100\n",
            "41403/41403 [==============================] - 13s 316us/step - loss: 14.2861\n",
            "Epoch 85/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.2858\n",
            "Epoch 86/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.2792\n",
            "Epoch 87/100\n",
            "41403/41403 [==============================] - 13s 320us/step - loss: 14.2752\n",
            "Epoch 88/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.2783\n",
            "Epoch 89/100\n",
            "41403/41403 [==============================] - 13s 317us/step - loss: 14.2806\n",
            "Epoch 90/100\n",
            "41403/41403 [==============================] - 13s 318us/step - loss: 14.2738\n",
            "Epoch 91/100\n",
            "41403/41403 [==============================] - 13s 324us/step - loss: 14.2720\n",
            "Epoch 92/100\n",
            "41403/41403 [==============================] - 14s 327us/step - loss: 14.2726\n",
            "Epoch 93/100\n",
            "41403/41403 [==============================] - 13s 325us/step - loss: 14.2681\n",
            "Epoch 94/100\n",
            "41403/41403 [==============================] - 14s 328us/step - loss: 14.2685\n",
            "Epoch 95/100\n",
            "41403/41403 [==============================] - 13s 323us/step - loss: 14.2661\n",
            "Epoch 96/100\n",
            "41403/41403 [==============================] - 13s 324us/step - loss: 14.2666\n",
            "Epoch 97/100\n",
            "41403/41403 [==============================] - 13s 326us/step - loss: 14.2668\n",
            "Epoch 98/100\n",
            "41403/41403 [==============================] - 13s 319us/step - loss: 14.2620\n",
            "Epoch 99/100\n",
            "41403/41403 [==============================] - 13s 322us/step - loss: 14.2658\n",
            "Epoch 100/100\n",
            "41403/41403 [==============================] - 13s 322us/step - loss: 14.2600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f665e3eaef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "ZPeFW_3L-mz_",
        "colab_type": "code",
        "outputId": "edabf704-f51a-4f77-9def-8bdd582e44c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jF0vlCqTHJOC",
        "colab_type": "code",
        "outputId": "1646d093-9e6e-4b86-bd96-c5f31da295ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "# print(source_vec[32221])\n",
        "# print(target_vec[36])\n",
        "# text=str(source[0])+'.'+str(source[1])\n",
        "print(source_vec.shape)\n",
        "try_m=source_vec[213:244]\n",
        "pred=model.predict(try_m)\n",
        "print(pred)\n",
        "# print(pred[224])\n",
        "# print(source_vec[12])\n",
        "# print(model.predict(source_vec[0]))\n",
        "# print(len(source[0]))\n",
        "# for s in source[2]:\n",
        "#   vec=vectorize_text(s)\n",
        "#   print(vec.shape)\n",
        "#   pred=model.predict(vec)\n",
        "#   print(pred)\n",
        "# ere=vectorize_text(source[2])\n",
        "# print(ere.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(41403, 3500)\n",
            "[[9.19788554e-02 9.16500241e-02 9.10192728e-02 ... 1.26146143e-14\n",
            "  1.20307300e-14 1.20752373e-14]\n",
            " [1.25485181e-03 7.37651271e-06 2.88824467e-05 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.45009363e-01 1.18840169e-02 2.26092964e-01 ... 1.89275711e-25\n",
            "  1.11128611e-25 1.19270912e-25]\n",
            " ...\n",
            " [4.28532576e-03 8.23761025e-12 1.24379555e-02 ... 2.97507001e-13\n",
            "  2.15142601e-13 1.60551178e-13]\n",
            " [1.25053212e-01 1.25871778e-01 1.23451665e-01 ... 7.42070428e-18\n",
            "  6.93971860e-18 7.72547070e-18]\n",
            " [8.90662894e-02 8.54089707e-02 8.46719071e-02 ... 2.31792485e-11\n",
            "  2.18902362e-11 2.10581413e-11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ZmEIOgCRMlb",
        "colab_type": "code",
        "outputId": "6d357ea7-661c-4d05-ede1-c505b0d3fbf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "print(predictions[10])\n",
        "text=source[0]\n",
        "def test(text):\n",
        "  text=str(text)\n",
        "  text_vec=vectorize_text(text)\n",
        "  results=model.predict(text_vec)\n",
        "  word_idx=sorted(range(len(results)), key=lambda i: lst[i], reverse=True)[:15]\n",
        "  for i in word_idx:\n",
        "    results[i]=1\n",
        "  for res in results:\n",
        "      print('##')\n",
        "      print( \" \".join([word for idx,word in enumerate(text.split(\" \")) if(res[idx] == 1)]) )\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9.2768952e-02 9.2036739e-02 8.6075410e-02 7.2006881e-02 8.3035894e-02\n",
            " 8.1244640e-02 8.1764631e-02 8.2747318e-02 8.5876934e-02 7.8830443e-02\n",
            " 7.6566115e-02 8.7046020e-02 8.6242062e-09 3.1908178e-14 3.3938084e-15\n",
            " 6.6952478e-15 1.1516922e-14 1.8075825e-14 1.4731428e-15 2.8180346e-15\n",
            " 3.5107614e-15 3.2163021e-15 2.9392710e-15 2.5641419e-15 2.9177212e-15\n",
            " 3.0298735e-15 2.8936354e-15 3.2966023e-15 4.2572439e-15 4.2644285e-15\n",
            " 3.4237747e-15 4.1406664e-15 4.4241238e-15 4.2321222e-15 3.5479946e-15]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}